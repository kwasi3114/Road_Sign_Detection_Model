{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# for this RCNN model, this tutorial was followed: https://towardsdatascience.com/step-by-step-r-cnn-implementation-from-scratch-in-python-e97101ccde55"
      ],
      "metadata": {
        "id": "1Bh6vHBYkge6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "M3ygpQnIThKc"
      },
      "outputs": [],
      "source": [
        "import os,cv2,keras\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()"
      ],
      "metadata": {
        "id": "mDPfsmONCvQz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_iou(bb1, bb2):\n",
        "    assert bb1['x1'] < bb1['x2']\n",
        "    assert bb1['y1'] < bb1['y2']\n",
        "    assert bb2['x1'] < bb2['x2']\n",
        "    assert bb2['y1'] < bb2['y2']\n",
        "\n",
        "    x_left = max(bb1['x1'], bb2['x1'])\n",
        "    y_top = max(bb1['y1'], bb2['y1'])\n",
        "    x_right = min(bb1['x2'], bb2['x2'])\n",
        "    y_bottom = min(bb1['y2'], bb2['y2'])\n",
        "\n",
        "    if x_right < x_left or y_bottom < y_top:\n",
        "        return 0.0\n",
        "\n",
        "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
        "\n",
        "    bb1_area = (bb1['x2'] - bb1['x1']) * (bb1['y2'] - bb1['y1'])\n",
        "    bb2_area = (bb2['x2'] - bb2['x1']) * (bb2['y2'] - bb2['y1'])\n",
        "\n",
        "    iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n",
        "    assert iou >= 0.0\n",
        "    assert iou <= 1.0\n",
        "    return iou"
      ],
      "metadata": {
        "id": "2Y92lczbc1QB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images=[]\n",
        "train_labels=[]\n",
        "#train_images = r'/content/Airplane Images'\n",
        "#train_labels = r'/content/Airplane Annotations'\n",
        "path = r'/content/Airplane Images'\n",
        "annot = r'/content/Airplane Annotations'\n",
        "for e,i in enumerate(os.listdir(annot)):\n",
        "    try:\n",
        "        if i.startswith(\"airplane\"):\n",
        "            filename = i.split(\".\")[0]+\".jpg\"\n",
        "            print(e,filename)\n",
        "            image = cv2.imread(os.path.join(path,filename))\n",
        "            df = pd.read_csv(os.path.join(annot,i))\n",
        "            gtvalues=[]\n",
        "            for row in df.iterrows():\n",
        "                x1 = int(row[1][0].split(\" \")[0])\n",
        "                y1 = int(row[1][0].split(\" \")[1])\n",
        "                x2 = int(row[1][0].split(\" \")[2])\n",
        "                y2 = int(row[1][0].split(\" \")[3])\n",
        "                gtvalues.append({\"x1\":x1,\"x2\":x2,\"y1\":y1,\"y2\":y2})\n",
        "            ss.setBaseImage(image)\n",
        "            ss.switchToSelectiveSearchFast()\n",
        "            ssresults = ss.process()\n",
        "            imout = image.copy()\n",
        "            counter = 0\n",
        "            falsecounter = 0\n",
        "            flag = 0\n",
        "            fflag = 0\n",
        "            bflag = 0\n",
        "            for e,result in enumerate(ssresults):\n",
        "                if e < 2000 and flag == 0:\n",
        "                    for gtval in gtvalues:\n",
        "                        x,y,w,h = result\n",
        "                        iou = get_iou(gtval,{\"x1\":x,\"x2\":x+w,\"y1\":y,\"y2\":y+h})\n",
        "                        if counter < 30:\n",
        "                            if iou > 0.70:\n",
        "                                timage = imout[y:y+h,x:x+w]\n",
        "                                resized = cv2.resize(timage, (224,224), interpolation = cv2.INTER_AREA)\n",
        "                                train_images.append(resized)\n",
        "                                train_labels.append(1)\n",
        "                                counter += 1\n",
        "                        else :\n",
        "                            fflag =1\n",
        "                        if falsecounter <30:\n",
        "                            if iou < 0.3:\n",
        "                                timage = imout[y:y+h,x:x+w]\n",
        "                                resized = cv2.resize(timage, (224,224), interpolation = cv2.INTER_AREA)\n",
        "                                train_images.append(resized)\n",
        "                                train_labels.append(0)\n",
        "                                falsecounter += 1\n",
        "                        else :\n",
        "                            bflag = 1\n",
        "                    if fflag == 1 and bflag == 1:\n",
        "                        print(\"inside\")\n",
        "                        flag = 1\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"error in \"+filename)\n",
        "        continue"
      ],
      "metadata": {
        "id": "OlTaYPZ3CyDg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0db9e8a8-8251-49c7-95e5-32c9f1fd32ac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 airplane_002.jpg\n",
            "1 airplane_001.jpg\n",
            "inside\n",
            "2 airplane_007.jpg\n",
            "inside\n",
            "3 airplane_006.jpg\n",
            "4 airplane_008.jpg\n",
            "5 airplane_003.jpg\n",
            "6 airplane_009.jpg\n",
            "7 airplane_005.jpg\n",
            "inside\n",
            "8 airplane_010.jpg\n",
            "9 airplane_004.jpg\n",
            "inside\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = np.array(train_images)\n",
        "y_new = np.array(train_labels)"
      ],
      "metadata": {
        "id": "KSBMN4LmC6fX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense\n",
        "from keras import Model\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.applications.vgg16 import VGG16\n",
        "vggmodel = VGG16(weights='imagenet', include_top=True)"
      ],
      "metadata": {
        "id": "ReS4Q6YrC9wH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layers in (vggmodel.layers)[:15]:\n",
        "    print(layers)\n",
        "    layers.trainable = False\n",
        "X= vggmodel.layers[-2].output\n",
        "predictions = Dense(2, activation=\"softmax\")(X)\n",
        "#model_final = Model(input = vggmodel.input, output = predictions)\n",
        "model_final = Model(vggmodel.input,predictions)\n",
        "opt = Adam(lr=0.0001)\n",
        "model_final.compile(loss = keras.losses.categorical_crossentropy, optimizer = opt, metrics=[\"accuracy\"])\n",
        "model_final.summary()"
      ],
      "metadata": {
        "id": "zzAnEQ7lC_gw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "464d075b-9dfa-40d5-bfa1-8369f4eac933"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.engine.input_layer.InputLayer object at 0x7f8da88603d0>\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f8da87f8910>\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f8da7f02fd0>\n",
            "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7f8da766b650>\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f8da3c98a10>\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f8da3c98110>\n",
            "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7f8da3c88850>\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f8da3c2b4d0>\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f8da3c30610>\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f8da3c300d0>\n",
            "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7f8da3ca7690>\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f8da3c40950>\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f8da3c3a150>\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f8da3c3a310>\n",
            "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7f8da3c580d0>\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 8194      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134,268,738\n",
            "Trainable params: 126,633,474\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "class MyLabelBinarizer(LabelBinarizer):\n",
        "    def transform(self, y):\n",
        "        Y = super().transform(y)\n",
        "        if self.y_type_ == 'binary':\n",
        "            return np.hstack((Y, 1-Y))\n",
        "        else:\n",
        "            return Y\n",
        "    def inverse_transform(self, Y, threshold=None):\n",
        "        if self.y_type_ == 'binary':\n",
        "            return super().inverse_transform(Y[:, 0], threshold)\n",
        "        else:\n",
        "            return super().inverse_transform(Y, threshold)\n",
        "lenc = MyLabelBinarizer()\n",
        "Y =  lenc.fit_transform(y_new)\n",
        "X_train, X_test , y_train, y_test = train_test_split(X_new,Y,test_size=0.10)"
      ],
      "metadata": {
        "id": "uJql1uUsDBJh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trdata = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rotation_range=90)\n",
        "traindata = trdata.flow(x=X_train, y=y_train)\n",
        "tsdata = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rotation_range=90)\n",
        "testdata = tsdata.flow(x=X_test, y=y_test)"
      ],
      "metadata": {
        "id": "a7V5nG0tDEAh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "checkpoint = ModelCheckpoint(\"ieeercnn_vgg16_1.h5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, mode='auto')\n",
        "hist = model_final.fit_generator(generator= traindata, steps_per_epoch= 1, epochs= 10, validation_data= testdata, validation_steps=2, callbacks=[checkpoint,early])"
      ],
      "metadata": {
        "id": "9Wz6FBJmDH7u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88e9a36a-5da2-4df1-9e61-e7c367941308"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3668 - accuracy: 0.2188\n",
            "Epoch 1: val_loss improved from inf to 1.26434, saving model to ieeercnn_vgg16_1.h5\n",
            "1/1 [==============================] - 57s 57s/step - loss: 1.3668 - accuracy: 0.2188 - val_loss: 1.2643 - val_accuracy: 0.8298\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.7161 - accuracy: 0.7812\n",
            "Epoch 2: val_loss improved from 1.26434 to 1.18807, saving model to ieeercnn_vgg16_1.h5\n",
            "1/1 [==============================] - 53s 53s/step - loss: 1.7161 - accuracy: 0.7812 - val_loss: 1.1881 - val_accuracy: 0.8511\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.7199 - accuracy: 0.5000\n",
            "Epoch 3: val_loss improved from 1.18807 to 0.69916, saving model to ieeercnn_vgg16_1.h5\n",
            "1/1 [==============================] - 35s 35s/step - loss: 6.7199 - accuracy: 0.5000 - val_loss: 0.6992 - val_accuracy: 0.8723\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4980 - accuracy: 0.8750\n",
            "Epoch 4: val_loss improved from 0.69916 to 0.46787, saving model to ieeercnn_vgg16_1.h5\n",
            "1/1 [==============================] - 53s 53s/step - loss: 0.4980 - accuracy: 0.8750 - val_loss: 0.4679 - val_accuracy: 0.7660\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.5476e-04 - accuracy: 1.0000\n",
            "Epoch 5: val_loss did not improve from 0.46787\n",
            "1/1 [==============================] - 28s 28s/step - loss: 3.5476e-04 - accuracy: 1.0000 - val_loss: 0.7271 - val_accuracy: 0.7660\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9485 - accuracy: 0.5312\n",
            "Epoch 6: val_loss did not improve from 0.46787\n",
            "1/1 [==============================] - 50s 50s/step - loss: 0.9485 - accuracy: 0.5312 - val_loss: 0.4980 - val_accuracy: 0.8298\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7449 - accuracy: 0.7188\n",
            "Epoch 7: val_loss improved from 0.46787 to 0.23797, saving model to ieeercnn_vgg16_1.h5\n",
            "1/1 [==============================] - 55s 55s/step - loss: 0.7449 - accuracy: 0.7188 - val_loss: 0.2380 - val_accuracy: 0.8723\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0254 - accuracy: 0.6250\n",
            "Epoch 8: val_loss did not improve from 0.23797\n",
            "1/1 [==============================] - 47s 47s/step - loss: 1.0254 - accuracy: 0.6250 - val_loss: 0.3714 - val_accuracy: 0.8511\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4328 - accuracy: 0.8750\n",
            "Epoch 9: val_loss did not improve from 0.23797\n",
            "1/1 [==============================] - 48s 48s/step - loss: 0.4328 - accuracy: 0.8750 - val_loss: 0.3633 - val_accuracy: 0.8936\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5272 - accuracy: 0.8125\n",
            "Epoch 10: val_loss did not improve from 0.23797\n",
            "1/1 [==============================] - 47s 47s/step - loss: 0.5272 - accuracy: 0.8125 - val_loss: 0.2919 - val_accuracy: 0.8298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z=0\n",
        "for e,i in enumerate(os.listdir(path)):\n",
        "    if i.startswith(\"4\"):\n",
        "        z += 1\n",
        "        img = cv2.imread(os.path.join(path,i))\n",
        "        ss.setBaseImage(img)\n",
        "        ss.switchToSelectiveSearchFast()\n",
        "        ssresults = ss.process()\n",
        "        imout = img.copy()\n",
        "        for e,result in enumerate(ssresults):\n",
        "            if e < 2000:\n",
        "                x,y,w,h = result\n",
        "                timage = imout[y:y+h,x:x+w]\n",
        "                resized = cv2.resize(timage, (224,224), interpolation = cv2.INTER_AREA)\n",
        "                img = np.expand_dims(resized, axis=0)\n",
        "                out= model_final.predict(img)\n",
        "                if out[0][0] > 0.70:\n",
        "                    cv2.rectangle(imout, (x, y), (x+w, y+h), (0, 255, 0), 1, cv2.LINE_AA)\n",
        "        plt.figure()\n",
        "        plt.imshow(imout)\n",
        "        break"
      ],
      "metadata": {
        "id": "5MtRV5FYDKeH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#graphs the accuracies of the training done above`\n",
        "epochs = np.array([1,2,3,4,5,6,7,8,9,10])\n",
        "accuracies = np.array([0.2188,0.7812,0.5,0.8750, 1, 0.5312, 0.7188, 0.625, 0.875, 0.8125])\n",
        "#above is the accuracies for my most recent test\n",
        "\n",
        "plt.plot(epochs, accuracies)\n",
        "plt.show"
      ],
      "metadata": {
        "id": "roJJXlSbDK9H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "77a7979d-276c-4b6f-a735-f6b0f637b406"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(*args, **kw)>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For my implementation, I decided to take a deper look into RCNN. To put it simply, RCNN is an extension of the standard CNN. RCNN has been improved on from the base CNN model in order to handle tasks in object detection, while the base CNN is more suited for image classification. For this particular implementation, I used a dataset to detect whether an airplane was in the image or not. \n",
        "\n",
        "The main metric I am using to measure success of the implementation is accuracy. I believe that an accuracy of at least .95 is required for something that would be implemented in actuality. The main reason the accuracy for my particular implementation was so low overall was due to me drastically scaling back the training for the sake of time. If I had actually used the full dataset and much more epochs, I am sure the accuracy would have met the benchmark of 0.95 at least. \n",
        "\n",
        "Like I mentioned above, in terms of improvements, the main thing I would do is a much more thorough training of the data. Another idea that comes to mind would be using images as varied as possible in order to help with any potential edge cases encountered in the process. I believe these two changes would greatly benefit the effectiveness of this model. \n"
      ],
      "metadata": {
        "id": "jG9PfzdefTlN"
      }
    }
  ]
}